{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import required dependencies and functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log in to instagram using username and password\n",
    "def log_in_to_instagram(username, password):\n",
    "    driver.find_element_by_xpath(\"//input[@name='username']\").send_keys('username')\n",
    "    driver.find_element_by_xpath(\"//input[@name='password']\").send_keys('password')\n",
    "    driver.find_element_by_xpath(\"//button[contains(.,'Log in')]\").click()\n",
    "\n",
    "#we will need this not to waste resourses while scrapping followers and following links\n",
    "def define_number_of_links(driver, account, regime=None):\n",
    "    #if number exceeds million, it should be retrieved from 'title' attribute of a tag\n",
    "    #else it can be retrieved as .text\n",
    "    if regime == 'followers':\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        try:\n",
    "            number_of_links = int(soup.find('ul').find_all('li')[1].span['title'].replace(',', ''))\n",
    "        except KeyError:\n",
    "            number_of_links = int(soup.find('ul').find_all('li')[1].text.split(' ')[0].replace(',', ''))\n",
    "        return number_of_links\n",
    "    elif regime == 'following':\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        try:\n",
    "            number_of_links = int(soup.find('ul').find_all('li')[2].span['title'].replace(',', ''))\n",
    "        except KeyError:\n",
    "            number_of_links = int(soup.find('ul').find_all('li')[2].text.split(' ')[0].replace(',', ''))\n",
    "        return number_of_links\n",
    "    else:\n",
    "        print('Please specify regime correctly, options: \"followers\", \"following\"')\n",
    "        return\n",
    "\n",
    "#Outputs two lists: followers and not_parsed (members of followers list that weren't parsed)\n",
    "def scrape_followers(driver, account):\n",
    "    driver.get(\"https://www.instagram.com/{0}/\".format(account))\n",
    "    #click to open followers list\n",
    "    driver.find_element_by_partial_link_text(\"follower\").click()\n",
    "    #element we can apply scrolling to\n",
    "    scroll_element = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[2]')\n",
    "    #make sure list loaded\n",
    "    time.sleep(3)\n",
    "    followers = []\n",
    "    not_parsed = []\n",
    "    #there we will use number_of_scrolls to save resourses (1 scroll = 12 people)\n",
    "    for i in range(define_number_of_links(driver, account, 'followers')//12 + 1):\n",
    "        scroll_element.send_keys(Keys.PAGE_DOWN)\n",
    "        #browser needs this to load new followers in the list\n",
    "        time.sleep(0.2)\n",
    "    #now enjoy classical parsing\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    followers_elems = soup.find_all('ul')[-1].find_all('li')\n",
    "    for fol in followers_elems:\n",
    "        try:\n",
    "            name = fol.a['href'].replace('/','')\n",
    "            followers.append(name)\n",
    "        except Exception as e:\n",
    "            print(f'Exception {e} while working with mister {fol}')\n",
    "            not_parsed.append(fol)\n",
    "            pass\n",
    "    return followers, not_parsed\n",
    "\n",
    "#Outputs two lists: following and not_parsed (members of following links list that weren't parsed)\n",
    "def scrape_following(driver, account):\n",
    "    driver.get(\"https://www.instagram.com/{0}/\".format(account))\n",
    "    #click to open following list\n",
    "    driver.find_element_by_partial_link_text(\"following\").click()\n",
    "    #element we can apply scrolling to\n",
    "    scroll_element = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[2]')\n",
    "    #make sure list loaded\n",
    "    time.sleep(3)\n",
    "    following = []\n",
    "    not_parsed = []\n",
    "    #there we will use number_of_scrolls to save resourses (1 scroll = 12 people)\n",
    "    for i in range(define_number_of_links(driver, account, 'following')//12 + 1):\n",
    "        scroll_element.send_keys(Keys.PAGE_DOWN)\n",
    "        #browser needs this to load new followers in the list\n",
    "        time.sleep(0.2)\n",
    "    #now enjoy classical parsing\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    following_elems = soup.find_all('ul')[-1].find_all('li')\n",
    "    for fol in following_elems:\n",
    "        try:\n",
    "            name = fol.a['href'].replace('/','')\n",
    "            following.append(name)\n",
    "        except Exception as e:\n",
    "            print(f'Exception {e} while working with mister {fol}')\n",
    "            not_parsed.append(fol)\n",
    "            pass\n",
    "    return following, not_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Start web driver</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use our web driver to scrape instagram followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.instagram.com/accounts/login/\"\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>To exploit instagramm at its full potential, log in is required</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_in_to_instagram('username', 'password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Usage</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "following, not_parsed = scrape_following(driver, 'mariapoga_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(following)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serandrew',\n",
       " 'marinamayer777',\n",
       " 'i_pracheva',\n",
       " 'dnk.russia',\n",
       " 'liubovcharity',\n",
       " 'mashapoga',\n",
       " 'sysoevl',\n",
       " 'schetnikovich',\n",
       " 'yanasapeta',\n",
       " 'aliona_hilt',\n",
       " 'sonya_neks_',\n",
       " 'glushdaria',\n",
       " 'karina_maksudova',\n",
       " 'pimenov.rus',\n",
       " 'alinabure',\n",
       " 'boshavoroshilova',\n",
       " 'nikitaefremov',\n",
       " 'satikazanova',\n",
       " 'nata_p1502',\n",
       " 'yulia.enhel',\n",
       " 'mirosmeister',\n",
       " 'borisovna_77',\n",
       " 'fc_ural',\n",
       " 'veraangel',\n",
       " 'zhdunovna',\n",
       " 'akif.tamince',\n",
       " 'stasanbro',\n",
       " 'mesutsoltay',\n",
       " 'arina_2003',\n",
       " 'darianorkina',\n",
       " 'iamzlatam',\n",
       " 'itsbatchaeva',\n",
       " '_rina_bombina_',\n",
       " 'evgeniyakukova',\n",
       " 'margarita_vn',\n",
       " 'gontveronika',\n",
       " 'marina_ross_atelier',\n",
       " 'masha_gridnevskaya',\n",
       " 'redgafur',\n",
       " 'butterfly_xtina',\n",
       " 'kruglikova_director',\n",
       " 'kisse__a',\n",
       " 'tariq_royal',\n",
       " 'irina_official.rus',\n",
       " 'veronika_krav',\n",
       " 'tatiana_v_lyalina',\n",
       " 'ekaterinamiga4eva',\n",
       " 'buslya',\n",
       " 'dmitry_bess2017',\n",
       " 'voguerussia',\n",
       " 'stepanov.i.dm',\n",
       " 'kalachikm',\n",
       " 'cheryshev90',\n",
       " 'grebenkina_official',\n",
       " 'oh_werner',\n",
       " 'yagnetinskaya',\n",
       " 'zaharov._ilya',\n",
       " 'katyagordon',\n",
       " 'elenabushina',\n",
       " 'nusr_et',\n",
       " 'miss_stom161',\n",
       " 'i.s.nesquik',\n",
       " 'liagureeva',\n",
       " 'space.lock',\n",
       " 'elenagord',\n",
       " 'zverevsuperstar',\n",
       " 'dressbymariashatalova',\n",
       " 'v_che_hair',\n",
       " 'poga8',\n",
       " 'aida.offi',\n",
       " 'airat_musin',\n",
       " 'lucysaxtonx',\n",
       " 'bfancy.salon',\n",
       " 'new_msk',\n",
       " 'tashevskaja',\n",
       " 'doctor_zubareva',\n",
       " 'mariapoga_podarki',\n",
       " 'juliaberetta1',\n",
       " 'vostrikova_k',\n",
       " 'isabella_muenchen',\n",
       " 'alena_aesthetic',\n",
       " 'ulyana_u_beauty',\n",
       " 'nd_norkinadaria',\n",
       " '_u_beauty',\n",
       " 'ladygynecolog',\n",
       " 'dmitry_darya',\n",
       " 'glory_book',\n",
       " 'ali_peregudova',\n",
       " 'annabelis5',\n",
       " 'marinatotal',\n",
       " 'dd_fashion_studio',\n",
       " 'fashionstyles4love',\n",
       " 'tkanicutur',\n",
       " 'spasol_spb',\n",
       " 'matildamylove',\n",
       " 'zimamoscow',\n",
       " 'nastyavainer',\n",
       " 'malafeeva_ekaterina',\n",
       " 'konstantinxaas',\n",
       " 'emmablinkova',\n",
       " 'natalia.tulpanova',\n",
       " 'elle_permanent',\n",
       " 'yana_koshkina_official',\n",
       " 'richtimegroup',\n",
       " 'ovoshi_masterskaya_buketov',\n",
       " 'sunplaceclub',\n",
       " 'ulianabelova',\n",
       " 'belova_style_',\n",
       " 'belova_style_page',\n",
       " 'romangorchakov',\n",
       " 'mariyasolodar',\n",
       " 'bes_natalia',\n",
       " 'ida_galich_life',\n",
       " 'irinygolubeva',\n",
       " 'danikahair',\n",
       " 'sofiesarenbrant',\n",
       " 'ayshatkadyrova',\n",
       " 'denizka27',\n",
       " 'alinadeligevurian',\n",
       " 'olgaulanova_',\n",
       " 'astrolog_andreeva',\n",
       " 'dianapegas',\n",
       " 'alisaselezneva__',\n",
       " 'juliawhitephoto',\n",
       " 'leila_shik_mua',\n",
       " '_fashion_planet__',\n",
       " 'eprosha',\n",
       " 'vrum_vrum_official',\n",
       " 'missalena.92',\n",
       " 'marina_ross__',\n",
       " 'u_lisovskaya',\n",
       " 'king_artem',\n",
       " 'vogue_palace',\n",
       " 'fshairdo',\n",
       " 'maryskashirokova',\n",
       " 'jetaime.ru',\n",
       " 'vardan_petrosyan',\n",
       " 'olgatamazovna',\n",
       " 'irinalux_svadba',\n",
       " 'yli.malykh96',\n",
       " 'kana.email.ru',\n",
       " 'pp_dunaevskaya_',\n",
       " 'fetish_km',\n",
       " 'photo.stas',\n",
       " 'ververa',\n",
       " 'adubrovskaya',\n",
       " 'mos_clinics_ru',\n",
       " 'showbiz_police',\n",
       " 'marinadegolle',\n",
       " 'aleksa___official',\n",
       " '_diamante_ru__',\n",
       " 'kovaleva_brand',\n",
       " 'mokka.life',\n",
       " 'serkhitrov',\n",
       " 'romabakardi',\n",
       " 'dokt0r_daffyy_']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Shut down web driver</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to close the web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
